# Polynomial-quadratic control design

The polynomial-quadratic regulator (PQR) is an extension to the Linear Quadratic Regulator (LQR). For continuous-time systems on the form,
```math
\dot{x} = f(x, u) = Ax + Bu + A_2 (x \otimes x) + A_3 (x \otimes x \otimes x) + \cdots
```
PQR finds a state-feedback controller ``u = K(x)`` that optimizes the familiar quadratic cost function
```math
J(x, u) = \int_0^\infty \left( x^T Q x + u^T R u \right) dt
```
where $Q$ and $R$ are symmetric positive definite matrices.

Here, the dynamics ``f`` is characterized by being polynomial in ``x`` and linear in ``u`` (input affine), while the cost is quadratic. If ``A_i = 0 \, \forall\,  i \geq 2``, PQR reduces to the familiar LQR controller. In many situations, non-polynomial terms in ``f`` can be approximated using polynomials using the function [`poly_approx`](@ref). Several examples of this will be shown below.

Polynomial-quadratic control problems can be solved using the function [`pqr`](@ref), which takes either ``f(x, u)`` as a function, or the matrices ``A`` and ``B`` as well as a vector of matrices ``N = \left[ A_2, A_3, \cdots \right]``.
`pqr` returns a `PQRSolution` which can be passed to [`build_K_function`](@ref) to perform code generation and return controller functions ``u = K(x)`` and ``K!(u, x)``. The solution can also be passed into the function [`predicted_cost`](@ref) to compute the predicted infinite-horizon cost achieved by the controller from a particular initial state.

## Example
The following example, which is taken from [^1], demonstrates how to use the PQR controller design to solve the Lorenz system with added control inputs:
```math
\begin{aligned}
\dot{x}_1(t) &= -10 x_1(t) + 10 x_2(t) + u(t) \\
\dot{x}_2(t) &= 28 x_1(t) - x_2(t)  - x_1(t)x_3(t)\\
\dot{x}_3(t) &= x_1(t)x_2(t) - 8/3 x_3(t) \\
\end{aligned}
```


We start by defining the system dynamics and cost function, and then solve the optimal control problem using [`pqr`](@ref). We then use [`build_K_function`](@ref) to generate a controller function ``u = K(x)`` and simulate the closed-loop system using [`solve`](@ref) from OrdinaryDiffEq. To compute the cost achieved by the controller, we add the cumulative integral of the cost as an additional state to the closed-loop dynamics and let the ODE integrator compute the integral for us. We compare this cost to the cost predicted by [`predicted_cost`](@ref) which uses the approximative value function obtained from solving the PQR problem (similar to the Ricatti solution obtained when solving an LQR problem).

[^1]: "On Approximating Polynomial-Quadratic Regulator Problems", Jeff Borggaard, Lizette Zietsman

```@example PQR
using DyadControlSystems, Test, Plots, LinearAlgebra, OrdinaryDiffEq, StaticArrays

nx = 3 # Number of state variables
nu = 1 # Number of control inputs
A = [
    -10 10 0
    28 -1 0
    0 0 -8/3
]
B = [1; 0; 0;;]
A2 = zeros(nx, nx^2)
A2[2,3] = A2[2,7] = -1/2
A2[3,2] = A2[3,4] = 1/2

Q = diagm(ones(3)) # State cost matrix
R = diagm(ones(1)) # Control input cost matrix

f = (x, u) -> A * x + B * u + A2 * kron(x, x) # Dynamics for simulation
l = (x, u) -> dot(x, Q, x) + dot(u, R, u)     # Cost function for simulation

function closed_loop(xc, (f,l,K), t)          # Closed-loop dynamics for simulation
    x = xc[1:end-1] # Last value is integral of cost
    u = K(x)
    dx = f(x, u)
    dc = l(x, u)
    [dx; dc]        # Return state and cost derivatives
end

x0 = Float64[10, 10, 10, 0] # Initial state, last value is integral of cost
tspan = (0.0, 50.0)
prob = ODEProblem(closed_loop, x0, tspan, (f, l, x->x))

# Design controller of degree 2
pqrsol = pqr(A, B, [A2], Q, R, 2) # It's possible to pass in f instead of A, B, A2
K, _ = build_K_function(pqrsol) # Returns u = K(x) and K!(u, x)
c = predicted_cost(pqrsol, x0[1:end-1])
@test c ≈ 7062.15 atol=0.02 # Compare to paper
sol = solve(prob, Rodas5P(), p=(f,l,K), reltol=1e-8, abstol=1e-8);
c = sol.u[end][end]
@test c ≈ 6911.03 rtol=1e-2 # Compare to paper

# Design controller of degree 4
pqrsol = pqr(A, B, [A2], Q, R, 4)
K, _ = build_K_function(pqrsol) 
c = predicted_cost(pqrsol, x0[1:end-1])
@test c ≈ 6924.27 atol=0.02
sol = solve(prob, Rodas5P(), p=(f,l,K), reltol=1e-8, abstol=1e-8);
c = sol.u[end][end]
@test c ≈ 6906.21 rtol=1e-2

# Simulate shorter horizon for plotting
sol = solve(prob, Rodas5P(), p=(f,l,K), tspan = (0, 2.5), reltol=1e-8, abstol=1e-8);
plot(sol, layout=4, title=["x1" "x2" "x3" "Cumulative cost"], legend=false, framestyle=:zerolines)
```

## Inspecting the controller ``K(x)`` and value function ``V(x)``
The controller ``K(x)`` generated by solving the PQR problem is a polynomial function of the state:
```math
K(x) = k_1 x + k_2 (x \otimes x) + k_3 (x \otimes x \otimes x) + \cdots
```
The struct `pqrsol::PQRSolution = pqr(...)` contains the fields `Ks::Vector{Matrix}` and `Vs::Vector{Matrix}`, where each entry in `Ks` corresponds to the `Ks[i] = k_i` arrays above. Similarly, `Vs` contains the matrices in the approximate value function ``V(x)`` (an approximate Lyapunov function, sometimes also called cost-to-go):
```math
V(x) = v_1 (x \otimes x) + v_2 (x \otimes x \otimes x) + \cdots
```
Note, the value function does not have a linear term like the controller does. The value function can be evaluated using the function [`predicted_cost`](@ref), which returns the predicted infinite-horizon cost from a particular state ``x``.

The controller corresponds to a polynomial, to have a look at this polynomial (rather than the matrices `Ks`), we can trace through it with symbolic variables. If we have obtained `K` from [`build_k_function`](@ref), we would do
```julia
using DyadControlSystems.DynamicPolynomials
@polyvar x[1:nx]
K(x)
```

if we haven't built a function, we could also do
```@example PQR
using DyadControlSystems.DynamicPolynomials
@polyvar x[1:nx] # Alternatively: Symbolics.@variables x[1:nx]
DyadControlSystems.Kfun(pqrsol, 2)(x) # Look at the second-degree controller
```
The controller is a now a vector of polynomials, in this case, there is only one entry since the system has a single input.


## Example with non-zero reference

The following example uses the same dynamical system as [Example: Dynamical extremum seeking](@ref)
```math
\begin{aligned}
\dot{x}_1(t) &= x_1(t)^2 + x_2(t) + u(t) \\
\dot{x}_1(t) &= x_1(t)^2 - x_2(t)\\
\end{aligned}
```
In the extremum-seeking example, the goal was to reach the unknown state and control input that optimized an performance function. In this example, we assume that the optimizing operating point is known, and design a polynomial-quadratic controller that stabilizes the system around this operating point. We thus create two versions of the dynamics, ``f`` operates in absolute coordinates, while ``fr`` operates in coordinates relative to the operating point ``\Delta x = x - x_r`` and ``\Delta u = u - u_r``. The controller is designed using ``f_r`` and operates in relative coordinates, but the closed-loop system is simulated using ``f`` and operates in absolute coordinates.

```@example PQR
xr = [0.5, 0.25]
ur = [-0.5]
f = function (x, u) # Operates in standard coordinates
    x1,x2 = x
    [
        x1^2 + x2 + u[]
        x1^2 - x2
    ]
end

fr = (Δx,Δu) -> f(Δx + xr, Δu + ur) # Operates in Δx, Δu coordinates

@assert f(xr, ur) ≈ [0, 0]                # Verify that xr, ur is an equilibrium point
@assert fr(zeros(2), zeros(1)) ≈ [0, 0]

function closed_loop_r(xc, (f,l,K), t) # Closed-loop dynamics for simulation
    x = xc[1:end-1] # Last value is integral of cost
    Δx = x - xr
    Δu = K(Δx)      # K operates on Δx
    u = Δu + ur 
    dx = f(x, u)
    dc = l(Δx, Δu)
    [dx; dc]        # Return state and cost derivatives
end

Q = I(2)
R = I(1)

pqrsol = pqr(fr, Q, R, 3)
time = 0:0.01:6
plot(layout=4)
for deg = 1:3
    K, _ = build_K_function(pqrsol, deg)
    prob = ODEProblem(closed_loop_r, zeros(3), (0.0, 6.0), (f, l, K))
    sol = solve(prob, Tsit5());
    plot!(sol, layout=3, title=["x1" "x2" "Cumulative cost"], lab="Degree $deg")
    u = map(time) do t
        x = sol(t)[1:end-1]
        K(x - xr) + ur
    end
    u = reduce(vcat, u)
    plot!(time, u, sp=4, title="u")
end
hline!(xr', c=:black, ls=:dash, label="Reference")
hline!(ur', c=:black, ls=:dash, label="Reference", sp=4)
```

The figure above compares the closed-loop response for different degrees of the controller, in this case, a second-order controller appears sufficient.


## Example: Quadrotor with non-affine inputs in MTK
This example will showcase a more realistic scenario that demonstrates a number of interesting things:
- How to use ModelingToolkit to model the system
- How to handle non-polynomial terms
- How to handle non-affine inputs

The system we will consider is a quadrotor with dynamics in a plane, that is, we consider one translation and one rotation degree of freedom. The dynamics are given by
```math
\begin{aligned}
\dot{y} &= v \\
\dot{v} &= -g + K_u \cos(\phi)u_1 \\
\dot{\phi} &= \omega \\
\dot{\omega} &= -d_0 \phi - d_1 ω + n_0 u_2
\end{aligned}
```
where ``y`` is the vertical position, ``v`` is the vertical velocity, ``\phi`` is the pitch angle, and ``\omega`` is the pitch rate. The control inputs are ``u_1`` which is the thrust, and ``u_2`` which is the pitching torque. The parameters ``K_u``, ``d_0``, ``d_1``, and ``n_0`` are constants, while ``g`` is the gravitational constant.

This model exhibits the following problematic aspects for the PQR controller design:
- The dynamics are non-polynomial due to the ``\cos`` term
- The input dynamics are non-affine due to the multiplication of the input ``u_1`` with a state-dependent term.

We will solve the first problem by approximating the ``\cos`` term using a third-order polynomial, and the second problem by introducing a low-pass filter on the control input ``u_1``. In [Exact handling of trigonometric terms](@ref) below, we show an alternative approach to handle trigonometric terms, by introducing additional state variables.

### Polynomial approximation
To approximate ``\cos(\phi)``, we could either linearize it (small-angle approximation), use a Taylor-approximation of higher degree, or perform a least-squares approximation over a certain interval. Here, we will take the latter approach, and use
```@example PQR
const cospoly = DyadControlSystems.poly_approx(cos, 5, -2, 2) |> splat(tuple)
```
to approximate ``\cos`` with a fifth-order polynomial over the interval ``[-2, 2]``rad. Unsurprisingly, we see that the odd terms are zero. We use these coefficients to define a function `cos5` that computes the approximate value of `cos` using the polynomial coefficients.

```@example PQR
cos5(x) = evalpoly(x, cospoly)
```

The approximation is reasonably accurate over the considered interval, much more accurate towards the edges than a Taylor approximation of the same degree:
```@example PQR
using Plots
gr(fmt=:png) # hide
plot([
        cos,
        cos5,
        x->1-x^2/2+x^4/24, # 5:th order Taylor approximation
    ],
    -2, 2,
    lab=["cos" "5:th order LS-approx" "5:th order Taylor approx"]
)
```

### Handling of non-affine inputs
The PQR design method assumes that ``u`` enters the dynamics linearly, i.e., like ``\dot x = \cdots + Bu`` where ``B`` is a matrix. Here, we have a term ``K_u \cos(\phi)u_1`` which is a nonlinear function of the input and a state variable ``\phi``. To handle this, we introduce a first-order low-pass filter on the input, after which the input ``u_1`` affects the filter state ``x_f`` linearly ``T \dot x_f = -x_f + u_1``, and the filter state instead appears in the equation ``K_u \cos(\phi)x_f``. This trick can actually be motivated from a physical perspective, since the motor that turns the propeller has its own dynamics and those are not included in the simple model above: a change in voltage across the motor is not going to result in an immediate change in thrust. Here, we model the motor dynamics as a first-order low-pass filter.

The full dynamics is now given by
```math
\begin{aligned}
\dot{y} &= v \\
\dot{v} &= -g + K_u \cos(\phi)x_f \\
\dot{\phi} &= \omega \\
\dot{\omega} &= -d_0 \phi - d_1 ω + n_0 u_2 \\
\dot{x}_f &= (-x_f + u_1) / T
\end{aligned}
```

### The system model
We are now ready to assemble the full model:
```@example PQR
using DyadControlSystems
using StaticArrays
using OrdinaryDiffEq
using ModelingToolkit
using ModelingToolkitStandardLibrary: Blocks
using ControlSystemsMTK
using Plots
using LinearAlgebra

gravity = 9.81
Ku = 0.89 / 1.4
d0 = 70
d1 = 17
n0 = 55

@named motor_dynamics = Blocks.FirstOrder(T = 0.001)

x0 = [0.85, 1, π/12, π/2]

@parameters t
@variables  ui(t)[1:2]=0
ui = collect(ui)
@variables y(t)=0.85 v(t)=1 ϕ(t)=π/12 ω(t)=π/2

D = Differential(t)

eqs = [
    D(y) ~ v,
    D(v) ~ -gravity + Ku * cos5(ϕ)*(motor_dynamics.output.u + gravity/Ku),
    D(ϕ) ~ ω,
    D(ω) ~ -d0 * ϕ - d1 * ω + n0 * ui[2],
    motor_dynamics.input.u ~ ui[1]
]

@named model = ODESystem(eqs, t; systems=[motor_dynamics])
```
Here, we applied additional steady-state gravity compensation to the control input by adding `gravity/Ku` to the input. This is not strictly necessary, but it makes the controller tuning simpler and we do not have to worry about integral action. In practice, we should of course handle also this if we intend to accurately control the altitude ``y``.

To obtain the dynamics in the form of a function ``\dot x = f(x, u, p, t)``, we construct a [`FunctionSystem`](@ref);
```@example PQR
quadrotor = FunctionSystem(model, ui, [y, ϕ])
(; nx, nu) = quadrotor
nothing # hide
```

### The cost function
To assemble the matrix ``Q``, we make use of the function `ControlSystemsMTK.build_quadratic_cost_matrix`. This function takes care of the fact that we have no control over the order in which the state variables appear in the state vector. However, to build the matrix ``R``, we can rely on the fact that the control inputs appear in the same order as they are defined when calling the `FunctionSystem` constructor above.
```@example PQR
R = diagm([1.0, 10.0])
Q = ControlSystemsMTK.build_quadratic_cost_matrix(model, ui,
    [y => 10, v => 10, ϕ => 1, ω => 0.01]
)
```

### Simulation
To perform a simulation, we first extract the default values of the parameters and initial conditions from the model, and then use these to define a function `f` that computes the closed-loop dynamics. We then use [`pqr`](@ref) to solve the PQR problem, and [`build_K_function`](@ref) to generate a controller function `u = K(x)` that computes the control input. We can then use `solve` from OrdinaryDiffEq to simulate the closed-loop system and plot the result. We compare the result for different degrees of the controller, 1 t0 3.

```@example PQR
tspan = (0.0, 8.0)
p = float.([ModelingToolkit.defaults(model)[p] for p in quadrotor.p])
x0sim = SVector(float.([ModelingToolkit.defaults(model)[p] for p in quadrotor.x])...)

f = (x,u)->quadrotor(x,u,p,nothing)
l = (x, u) -> dot(x, Q, x) + dot(u, R, u)

"Closed-loop dynamics with cumulative cost added as last state variable"
function f_closed_loop(xc, K, t)
    x = xc[1:end-1]
    u = K(x)
    ẋ = quadrotor(x, u, p, nothing)
    [ẋ; l(x, u)]
end
prob = ODEProblem(f_closed_loop, [x0sim; 0], tspan, x->x)

pqrsol = pqr(f, Q, R, 3) 

fig = plot(layout=8)
for deg in 1:3
    K, _ = build_K_function(pqrsol, deg)
    @info "Simulating degree $deg"
    sol = solve(prob, Tsit5(), p = K, saveat=0.01)
    plot!(sol, title=permutedims([state_names(quadrotor); "Cost"]), lab="Degree $deg")
    time = range(tspan..., 100)
    uv = map(time) do t
        x = sol(t)
        K(x[1:end-1])
    end
    um = reduce(hcat, uv)'
    plot!(time, um, title=permutedims(input_names(quadrotor)), sp=(1:2)' .+ (nx+1), lab="Degree $deg")
end
fig
```

If we start the simulation further away from the origin (5x further away than above), we need to re-tune the weights a bit for the controller to perform well. In this case, it's enough to increase the penalty on the pitch-torque input in order for the controller not to perform too aggressive pitching motions that bring the system too far away from the validity region of our polynomial approximation to ``\cos``. This time, we add also a degree 5 controller since we are expecting a higher-order controller to perform better further away from the origin.
```@example PQR
R = diagm([1.0, 100.0])
pqrsol = pqr(f, Q, R, 5) 
fig = plot(layout=9)
for deg in 1:2:5
    K, _ = build_K_function(pqrsol, deg)
    sol = solve(prob, Tsit5(), p = K, u0 = [5x0sim; 0], saveat=0.01)
    lab = "Degree $deg"
    plot!(sol; title=permutedims([state_names(quadrotor); "Cost"]), lab)
    time = range(tspan..., 100)
    uv = map(time) do t
        x = sol(t)
        K(x[1:end-1]) # Reconstruct control input for plotting
    end
    um = reduce(hcat, uv)'
    plot!(time, um; title=permutedims(input_names(quadrotor)), sp=(1:2)' .+ (nx+1), lab)

    # Evaluate approximate Lyapunov function along trajectory
    Vt = [predicted_cost(pqrsol, sol(t)[1:nx]) for t in time]
    plot!(time, Vt; title="Lyapunov function V(x)", sp=9, lab)
end
fig
```

## Exact handling of trigonometric terms
In the example with the quadrotor above, we performed a polynomial least-squares approximation of the trigonometric term in order to enable PQR design. Simple trigonometric terms can also be handled exactly by introducing two new state variables: ``s = \sin(\phi)`` and ``c = \cos(\phi)``. The dynamics are then given by
```math
\begin{aligned}
\dot{x}_f &= (-x_f + u_1) / \tau \\
\dot{y} &= v \\
\dot{v} &= -g + K_u c x_f \\
\dot{\phi} &= \omega \\
\dot{\omega} &= -d_0 \phi - d_1 ω + n_0 u_2 \\
\dot{s} &= c \omega \\
\dot{c} &= -s \omega
\end{aligned}
```
here, we use the same trick as in [Handling of non-affine inputs](@ref) to handle the nonlinear input term ``K_u \cos(\phi)u_1``. The dynamics are now polynomial in the state and input, and we can use PQR to design a controller. One problem that will arise when adding the two new state variables is that the resulting system is not linearly controllable in the origin, and the solver for the Ricatti equation will fail when trying to find the first-order feedback gain. This is handled automatically by [`pqr`](@ref), which will perform model-order reduction and design a feedback gain for the controllable subsystem.

Another slight complication is that the state variables ``s`` and ``c`` are fictional, and we must thus compute those as part of the controller. Below, we demonstrate the workflow for this approach. We 
1. Define the system dynamics in expanded form, `polyquad`, and use this function for the [`pqr`](@ref) design.
2. Define the system dynamics standard form, `quad`, and use this function for simulation.
3. Define the closed-loop system dynamics, `f_cl_polyquad`, where we compute the extended state `xe = [x; sin(x[4]); cos(x[4])]` that serves as the input to the controller.
4. Simulate and plot the result.

```@example PQR
using DyadControlSystems, OrdinaryDiffEq, Plots, LinearAlgebra

function polyquad(state, u, p, t)
    g = 9.81; Ku = 0.89 / 1.4; d0 = 70; d1 = 17; n0 = 55; τ = 0.001
    xf, y, v, ϕ, ω, s, c = state
    [
        (-xf + u[1]) / τ
        v
        -g + Ku * c * xf
        ω
        -d0 * ϕ - d1 * ω + n0 * u[2]
        c*ω
        -s*ω
    ]
end

function quad(state, u, p, t)
    g = 9.81; Ku = 0.89 / 1.4; d0 = 70; d1 = 17; n0 = 55; τ = 0.001
    xf, y, v, ϕ, ω = state
    [
        (-xf + u[1]) / τ
        v
        -g + Ku * cos(ϕ) * xf
        ω
        -d0 * ϕ - d1 * ω + n0 * u[2]
    ]
end

ϵ = 1e-6
nx = 5 # State dimension of original dynamics
nu = 2 # Input dimension

Q = diagm(Float64[ϵ, 10, 10, 1, 0.01, ϵ, ϵ])
R = diagm(Float64[1, 100])

xr = [0,0,0,0,0,sin(0), cos(0)] # Reference state
ur = [9.81/(0.89 / 1.4), 0]     # Reference input (counteract gravity using u1)
fr = (Δx,Δu) -> polyquad(Δx + xr, Δu + ur, 0, 0) # Dynamics that operates in Δx, Δu coordinates

pqrsol = pqr(fr, Q, R, 3)

function f_cl_polyquad(xc, K, t)
    x = xc[1:end-1]
    xe = [x; sin(x[4]); cos(x[4])]
    Δx = xe - xr
    Δu = K(Δx)
    u = Δu + ur
    dx = quad(x, u, 0, t)
    dc = dot(Δx, Q, Δx) + dot(Δu, R, Δu) # Cost integrand
    [dx; dc]
end

x0 = 5*[0, 0.85, 1, π/12, π/2, 0] # Initial state, last value is integral of cost
tspan = (0.0, 8.0)
prob = ODEProblem(f_cl_polyquad, x0, tspan)

fig = plot(layout=nx+3)
for deg in [1,3]
    K, _ = build_K_function(pqrsol, deg)
    sol = solve(prob, Tsit5(), p = K, saveat=0.01)

    t = range(tspan..., 300)
    ui = map(t) do t
        x = sol(t)[1:end-1]
        xe = [x; sin(x[4]); cos(x[4])]
        K(xe-xr)
    end
    ui = reduce(hcat, ui)'
    lab = "deg=$deg"
    plot!(sol; title=["xf" "y" "v" "ϕ" "ω" "cost"], lab)
    plot!(t, ui; sp=(1:nu)' .+ (nx+1), title=["u1" "u2"], lab)
end
fig
```

## Vector-valued polynomial approximation
Above, we approximated trigonometric functions using low-order polynomials. However, we can also approximate complete vector-valued dynamics functions using polynomials. The function [`poly_approx`](@ref) takes a vector-valued dynamics function `ẋ = f(x, u)`, lower and upper bounds on the domain of ``x`` and ``u`` as well as the monomial degrees for each state variables `x[i]`.

In the example below, we will demonstrate PQR control design for a pendulum on a cart.

## PQR for pendulum on cart
We choose a coordinate system such that ``\phi = 0`` corresponds to the pendulum pointing upwards (the unstable equilibrium). The state is comprised of
```math
x = [p, \phi, v, \dot \phi, x_f]
```
where ``p`` is the position of the cart, ``\phi`` is the angle of the pendulum, ``v`` is the velocity of the cart, ``\dot \phi`` is the angular velocity of the pendulum, and ``x_f`` is the state of the motor dynamics. The input is the commanded force to be applied to the cart.

```@example PQR
function cartpole(x, u, p, t)
    mc, mp, l, g = 1.0, 0.2, 0.5, 9.81
    τ = 0.001

    ϕ  = x[2] - π # Origin is now at upward equilibrium
    qd = x[SA[3, 4]]
    xf = x[5] # Filter state
    s = sin(ϕ)
    c = cos(ϕ)

    H = [mc+mp mp*l*c; mp*l*c mp*l^2]
    C = [0 -mp*qd[2]*l*s; 0 0]
    G = [0, mp * g * l * s]
    B = [1, 0]
    qdd = -H \ (C * qd + G - B * xf)
    dxf = (-xf + u[1]) / τ
    return [qd; qdd; dxf]
end

nx = 5
nu = 1

l = (x, u) -> dot(x, Q, x) + dot(u, R, u)
f = (x, u) -> cartpole(x, u, 0, 0)
```
To approximate the function `cartpole` using polynomials, we choose upper and lower bounds for the state and inputs, ``l_x``, ``u_x``, ``l_u``, and ``u_u``. We also choose a degree `deg` for the polynomial approximation of the state dynamics, `deg` can be a single integer, or a vector of the same length as the number of state variables. In the latter case, monomials of `x[i]` including up to degree `deg[i]` are included. Here, we choose a high degree for the angle state ``\phi`` to accurately capture the nonlinearity over a reasonably large domain, but lower orders for the other state variables. We approximate the trigonometric terms over the domain ``±0.4\pi`` only, since the accuracy of the approximation appear to be more important close to the unstable equilibrium than far away from it. The function [`poly_approx`](@ref) returns a function special struct that can be passed to [`pqr`](@ref) in place of the standard dynamics function.

```@example PQR
deg = [1, 5, 2, 2, 1] # p, ϕ, v, dϕ, xf
ux = [4, 0.4pi, 5, 5, 100]
lx = -ux
uu = fill(10, nu)
lu = -uu
cartpole_pol = DyadControlSystems.poly_approx(f; deg, ux, lx, uu, lu)
```

Next, we define the quadratic cost matrices ``Q, R`` and solve the PQR problem. We then generate a controller function `u = K(x)` using [`build_K_function`](@ref) and simulate the closed-loop system using `solve` from OrdinaryDiffEq. To compute the cost achieved by the controller, we add the cumulative integral of the cost as an additional state to the closed-loop dynamics and let the ODE integrator compute the integral for us. We also define a function `wrap_angle` that makes sure that the angle stays within the interval `[-π, π]`.

```@example PQR
R = diagm([0.2])
Q = diagm(Float64[2,1,0.1,1,1e-6])
pqrsol = pqr(cartpole_pol, Q, R, maximum(deg))

wrap_angle(x::Number) = mod(x+pi, 2pi)-pi
wrap_angle(x) = [x[1], wrap_angle(x[2]), x[3], x[4], x[5]]

function f_cl_cartpole(xc, (f,l,K), t)
    x  = xc[1:end-1] # Last value is integral of cost
    Δx = wrap_angle(x)
    th = 100 # Input saturation
    Δu = clamp.(K(Δx), -th, th) 
    dx = f(x, Δu)
    dc = l(Δx, Δu)
    [dx; dc]         # Return state and cost derivatives
end
x0 = [0, pi-deg2rad(15), 0, 0, 0, 0] # Initial state, start 15° from the downward equilibrium. This avoids the the initial chattering close to the downward equilibrium.

tspan = (0.0, 9.0)
prob = ODEProblem(f_cl_cartpole, x0, tspan, (f, l, x->x))

fig = plot(layout=nx+1)
for d = [3, 5]
    K, _ = build_K_function(pqrsol, d, simplify=false)
    sol = solve(prob, Tsit5(), reltol=1e-5, abstol=1e-5, p=(f, l, K))
    plot!(sol, layout=nx+1, title=["x" "ϕ" "dx" "dϕ" "u" "cost"], lab="Deg $d")
end
fig
```

Controllers of degrees 3 and 5 manage to swing the pendulum up (upward equilibria are located at ``\phi = 0 ± 2π``), but controllers of lower order do not. Note, that the PQR controller does not handle input saturation explicitly, and as a consequence, does not perform nearly as well swinging the pendulum up as if trajectory optimization had been used. An example of pendulum swing-up with these dynamics is provided in [Pendulum swing-up](@ref).



## Index

```@index
Pages = ["pqr.md"]
```
```@autodocs
Modules = [DyadControlSystems]
Pages = ["pqr.jl"]
Private = false
```